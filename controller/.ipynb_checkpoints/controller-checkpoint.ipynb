{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import requests\n",
    "\n",
    "WIND_X = 640\n",
    "WIND_Y = 480\n",
    "\n",
    "BACKGROUND_COLOR = (150, 160, 170)\n",
    "\n",
    "def get_available_cameras (upper_bound = 10, lower_bound = 0):\n",
    "    available = []\n",
    "    \n",
    "    for i in range (lower_bound, upper_bound):\n",
    "        cap = cv2.VideoCapture (i)\n",
    "    \n",
    "        if (cap.isOpened ()):\n",
    "            available.append (i)\n",
    "    \n",
    "        cap.release ()\n",
    "    \n",
    "    return available\n",
    "\n",
    "get_available_cameras ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(x_array, y_array):\n",
    "        rectangle_calibrovka = [0, 0, 0, 0]\n",
    "        ###find top position###\n",
    "        top = [0, 0]\n",
    "        for i in range(len(y_array)):\n",
    "            if y_array[i] > top[1]:\n",
    "                top[0] = x_array[i]\n",
    "                top[1] = y_array[i]\n",
    "        ###find left position###\n",
    "        left = [0, 0]\n",
    "        left[0] = 10e10\n",
    "        for i in range(len(x_array)):\n",
    "            if x_array[i] < left[0]:\n",
    "                left[0] = x_array[i]\n",
    "                left[1] = y_array[i]\n",
    "        ###find right position###\n",
    "        right = [0, 0]\n",
    "        right[0] = 0\n",
    "        for i in range(len(x_array)):\n",
    "            if x_array[i] > right[0]:\n",
    "                right[0] = x_array[i]\n",
    "                right[1] = y_array[i]\n",
    "        ###find botom position###\n",
    "        bottom = [0, 0]\n",
    "        bottom[1] = 10e10\n",
    "        for i in range(len(y_array)):\n",
    "            if y_array[i] < bottom[1]:\n",
    "                bottom[0] = x_array[i]\n",
    "                bottom[1] = y_array[i]\n",
    "        #cv2.rectangle(img,(left[0], up[1]),(right[0]+dev1, down[1]+dev2),(255,0,255),3)\n",
    "            \n",
    "        rectangle_calibrovka[0] = left[0]\n",
    "        rectangle_calibrovka[1] = top[1]\n",
    "        rectangle_calibrovka[2] = right[0]#+size_cell_x\n",
    "        rectangle_calibrovka[3] = bottom[1]#+size_cell_y\n",
    "                    \n",
    "        return rectangle_calibrovka\n",
    "\n",
    "def detect_marker (img, color):\n",
    "    #color = [hsv_min, hsv_max]\n",
    "    \n",
    "    # преобразуем RGB картинку в HSV модель\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # применяем цветовой фильтр\n",
    "\n",
    "    thresh = cv2.inRange(hsv, color[0], color[1])\n",
    "    \n",
    "    # вычисляем моменты изображения\n",
    "    moments = cv2.moments(thresh, 1)\n",
    "    dM01 = moments['m01']\n",
    "    dM10 = moments['m10']\n",
    "    dArea = moments['m00']\n",
    "    # будем реагировать только на те моменты,\n",
    "    # которые содержать больше 100 пикселей\n",
    "    \n",
    "    marker_coord = [0, 0]\n",
    "    if dArea > 100:\n",
    "        x = int(dM10 / dArea)\n",
    "        y = int(dM01 / dArea)\n",
    "        marker_coord[0] = x\n",
    "        marker_coord[1] = y\n",
    "        #cv2.circle(img, (x, y), 10, (0,0,255), -1)\n",
    "    return marker_coord\n",
    "\n",
    "def find_marker_place (img, marker_coord, size_cell_x, size_cell_y, color):\n",
    "    coord_rectang = [0, 0, 0, 0]\n",
    "    k_i = 0\n",
    "    l_j = 0\n",
    "    while k_i <= img.shape[1]:\n",
    "        while l_j <= img.shape[0]:\n",
    "            if x < k_i + size_cell_x and x > k_i and y < l_j + size_cell_y and y > l_j:\n",
    "                coord_rectang[0] = k_i\n",
    "                coord_rectang[1] = l_j\n",
    "                coord_rectang[2] = k_i+size_cell_x\n",
    "                coord_rectang[3] = l_j+size_cell_y\n",
    "                #cv2.rectangle(img,(k_i, l_j),(k_i+dev1, l_j+dev2),(0,255,255),3)                  \n",
    "            l_j+= dev2\n",
    "        k_i+= dev1\n",
    "        l_j = 0\n",
    "        \n",
    "    return coord_rectang\n",
    "\n",
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    \n",
    "    lst = list(dim)\n",
    "    lst[0] = int(lst[0])\n",
    "    dim = tuple(lst)\n",
    "    \n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    \n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    "\n",
    "def find_movement_of_man (curr_frame, back_frame, connectivity = 4):\n",
    "    \n",
    "    #shape\n",
    "    shape = curr_frame.shape\n",
    "    \n",
    "    #make a photo of curr_frame\n",
    "    new_frame = cv2.imwrite('opencv1.png', curr_frame)\n",
    "    \n",
    "    #make a resize\n",
    "    back_frame_resize = image_resize(back_frame , width = shape[1]/4, height = shape[0]/4)\n",
    "    new_frame_resize = image_resize(new_frame , width = shape[1]/4, height = shape[0]/4)\n",
    "    \n",
    "    #filter\n",
    "    filtered_back_frame = cv2.blur (back_frame, (9, 9))\n",
    "    filtered_new_frame = cv2.blur (new_frame, (9, 9))\n",
    "    \n",
    "    #difference between photos\n",
    "    diff_between = cv2.absdiff(filtered_back_frame,filtered_new_frame)\n",
    "    \n",
    "\n",
    "    img_grey = cv2.cvtColor(diff_between, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gaussian_blur = cv2.GaussianBlur(img_grey, (5,5), 0)\n",
    "    \n",
    "    #binarization\n",
    "    _, frame = cv2.threshold(gaussian_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    kernel = np.ones((10,10),np.uint8)\n",
    "    erosia = cv2.erode(frame,kernel,iterations = 1)\n",
    "    \n",
    "    frame_end = image_resize(erosia , width = sh[1], height = sh[0])\n",
    "    \n",
    "    #find the lagest component of connectivity\n",
    "    output = cv2.connectedComponentsWithStats(d, connectivity, cv2.CV_32S)\n",
    "    \n",
    "    #rectangle around area\n",
    "    \n",
    "    new_rectangle_coord = [0, 0, 0, 0]\n",
    "    for i in range(output[0]):\n",
    "            if output[2][i][4] >= 5000: \n",
    "                new_rectangle_coord[0] = output[2][i][0]\n",
    "                new_rectangle_coord[1] = output[2][i][1]\n",
    "                new_rectangle_coord[2] = output[2][i][0] + output[2][i][2]\n",
    "                new_rectangle_coord[3] = output[2][i][1] + output[2][i][3]\n",
    "                #cv2.rectangle(d, (output[2][i][0], output[2][i][1]), \n",
    "                ####(output[2][i][0] + output[2][i][2], output[2][i][1] + output[2][i][3]), (255,0,255), 2)\n",
    "    \n",
    "    return new_rectangle_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow (\"controller\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow (\"controller\", (WIND_X * 2, WIND_Y))\n",
    "\n",
    "cam = cv2.VideoCapture (1)\n",
    "ret, initial_frame = cam.read ()\n",
    "\n",
    "background = initial_frame.copy ()\n",
    "\n",
    "#measurements_num = 6 #measurements per series\n",
    "#series_num = 2\n",
    "\n",
    "time_limit     = 10000\n",
    "measuring_mode = False\n",
    "movement_type  = 1\n",
    "\n",
    "start_time         = 0\n",
    "current_time       = 0\n",
    "time_passed        = 0\n",
    "robot_command_sent = False\n",
    "\n",
    "relax_mode    = False\n",
    "relax_timeout = 5\n",
    "\n",
    "marker_color_min = (0, 140, 60)\n",
    "marker_color_max = (30, 160, 90)\n",
    "\n",
    "calibration_mode = False\n",
    "\n",
    "curr_measurement_finished = False\n",
    "\n",
    "curr_time = time.time ()\n",
    "files_common_part = str (curr_time)\n",
    "\n",
    "fourcc1 = cv2.VideoWriter_fourcc (*'XVID')\n",
    "stream  = cv2.VideoWriter (\"log/\" + files_common_part + 'stream' + '.avi', fourcc1, 20.0, (WIND_X, WIND_Y))\n",
    "\n",
    "fourcc2 = cv2.VideoWriter_fourcc (*'XVID')\n",
    "cv      = cv2.VideoWriter (\"log/\" + files_common_part + 'cv' + '.avi', fourcc2, 20.0, (WIND_X, WIND_Y))\n",
    "\n",
    "log = open (\"log/\" + files_common_part + \"log.txt\", 'w')\n",
    "\n",
    "calib_marker_x = []\n",
    "calib_marker_y = []\n",
    "\n",
    "ip = \"http://192.168.43.201:\"\n",
    "port = \"9559\"\n",
    "\n",
    "rect_calib = [100, 100, 300, 250]\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cam.read ()\n",
    "    \n",
    "    stream.write (frame)\n",
    "    cv.write     (frame)\n",
    "    log.write (\"ffuu\")\n",
    "    \n",
    "    cv2.waitKey (1)\n",
    "    \n",
    "    frame_resized = cv2.resize (frame, (WIND_X, WIND_Y))\n",
    "    \n",
    "    current_time = time.time ()\n",
    "    time_passed = current_time - start_time\n",
    "    \n",
    "    marker = detect_marker (frame, (marker_color_min, marker_color_max))\n",
    "    \n",
    "    if (measuring_mode == True and relax_mode == False):\n",
    "        #send command to robot\n",
    "        if (robot_command_sent == False):\n",
    "            #wget ....\n",
    "            #os.system (\"wget \" + '\"' + ip + port + \"/?action=/hands_up&text=kek\")\n",
    "\n",
    "            r = requests.get (\"http://192.168.1.250:9559/?action=red&text=qwer\")\n",
    "            \n",
    "            #play sound\n",
    "            robot_command_sent = True\n",
    "        \n",
    "        marker = detect_marker (frame, (marker_color_min, marker_color_max))\n",
    "        \n",
    "        #if (cv says \"done\"):\n",
    "        if (marker [1] < rect_calib [1] + (rect_calib [3] - rect_calib [1]) / 3):\n",
    "            print (\"success\")\n",
    "            #send command to haptics\n",
    "            curr_measurement_finished = True\n",
    "        \n",
    "        if (time_passed > time_limit):\n",
    "            curr_measurement_finished = True\n",
    "    \n",
    "    if (curr_measurement_finished == True):\n",
    "        #hands down to robot\n",
    "        curr_measurement_finished = False\n",
    "        relax_mode = True\n",
    "        start_time = current_time\n",
    "        time_passed = 0\n",
    "    \n",
    "    if (relax_mode == True):\n",
    "        print (\"relax\")\n",
    "        \n",
    "        if (time_passed > relax_timeout):\n",
    "            relax_mode = False\n",
    "            start_time = current_time\n",
    "            time_passed = 0\n",
    "        \n",
    "    analysis = frame_resized.copy ()\n",
    "    cv2.rectangle (analysis, (0, 0), (WIND_X, WIND_Y), BACKGROUND_COLOR, thickness = -1)\n",
    "    \n",
    "    cv2.rectangle (frame_resized, (int (rect_calib [0]), int (rect_calib [1])),\n",
    "                   (int (rect_calib [2]), int (rect_calib [3])),\n",
    "                   (100, 200, 100), thickness = 5)\n",
    "    \n",
    "    cv2.circle (frame_resized, (marker [0], marker [1]), 10, (0,0,255), -1)\n",
    "\n",
    "    if (calibration_mode == True):\n",
    "        marker = detect_marker (frame, (marker_color_min, marker_color_max))\n",
    "        calib_marker_x.append (marker [0])\n",
    "        calib_marker_y.append (marker [1])\n",
    "        \n",
    "        cv2.circle (analysis, (marker [0], marker [1]), 10, (0,0,255), -1)\n",
    "\n",
    "    #text\n",
    "    #time left to the end of the measurement\n",
    "    #number of current measurement/total number of measurements\n",
    "    #type of the movement\n",
    "    \n",
    "    #записать картинки в файлы\n",
    "    \n",
    "    output = np.concatenate ((frame_resized, analysis), axis = 1)    \n",
    "    #output = np.concatenate ((frame_resized, background), axis = 1)    \n",
    "\n",
    "    cv2.imshow (\"controller\", output)\n",
    "    \n",
    "    time.sleep (0.01)\n",
    "    keyb = cv2.waitKey (1)\n",
    "    \n",
    "    if (keyb & 0xFF == ord ('q')):\n",
    "        break\n",
    "\n",
    "    elif (keyb & 0xFF == ord ('s')):\n",
    "        measuring_mode = True\n",
    "        start_time = time.time ()\n",
    "\n",
    "    elif (keyb & 0xFF == ord ('f')):\n",
    "        measuring_mode = False\n",
    "\n",
    "    elif (keyb & 0xFF == ord ('1')):\n",
    "        movement_type = 1\n",
    "\n",
    "    elif (keyb & 0xFF == ord ('2')):\n",
    "        movement_type = 2\n",
    "    \n",
    "    elif (keyb & 0xFF == ord ('3')):\n",
    "        movement_type = 3\n",
    "    \n",
    "    #take background photo\n",
    "    elif (keyb & 0xFF == ord ('b')):\n",
    "        background = frame\n",
    "    \n",
    "    #start calibration\n",
    "    elif (keyb & 0xFF == ord ('c')):\n",
    "        calibration_mode = True\n",
    "    \n",
    "    #stop calibration\n",
    "    elif (keyb & 0xFF == ord ('v')):\n",
    "        calibration_mode = False\n",
    "        rect_calib = calibration (calib_marker_x, calib_marker_y)\n",
    "        calib_marker_x.clear ()\n",
    "        calib_marker_y.clear ()\n",
    "    \n",
    "cam.release ()\n",
    "\n",
    "#закрыть файлы\n",
    "stream.release ()\n",
    "cv.release     ()\n",
    "log.close    ()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import requests\n",
    "import serial\n",
    "import PyCmdMessenger\n",
    "from pygame import mixer\n",
    "\n",
    "WIND_X = int (1280)\n",
    "WIND_Y = int (720)\n",
    "\n",
    "BACKGROUND_COLOR = (150, 160, 170)\n",
    "\n",
    "def get_available_cameras (upper_bound = 10, lower_bound = 0):\n",
    "    available = []\n",
    "    \n",
    "    for i in range (lower_bound, upper_bound):\n",
    "        cap = cv2.VideoCapture (i)\n",
    "    \n",
    "        if (cap.isOpened ()):\n",
    "            available.append (i)\n",
    "    \n",
    "        cap.release ()\n",
    "    \n",
    "    return available\n",
    "\n",
    "def calibration(x_array, y_array):\n",
    "        rectangle_calibrovka = [0, 0, 0, 0]\n",
    "        ###find top position###\n",
    "        top = [0, 0]\n",
    "        for i in range(len(y_array)):\n",
    "            if y_array[i] > top[1]:\n",
    "                top[0] = x_array[i]\n",
    "                top[1] = y_array[i]\n",
    "        ###find left position###\n",
    "        left = [0, 0]\n",
    "        left[0] = 10e5\n",
    "        for i in range(len(x_array)):\n",
    "            if x_array[i] < left[0]:\n",
    "                left[0] = x_array[i]\n",
    "                left[1] = y_array[i]\n",
    "        ###find right position###\n",
    "        right = [0, 0]\n",
    "        right[0] = 0\n",
    "        for i in range(len(x_array)):\n",
    "            if x_array[i] > right[0]:\n",
    "                right[0] = x_array[i]\n",
    "                right[1] = y_array[i]\n",
    "        ###find botom position###\n",
    "        bottom = [0, 0]\n",
    "        bottom[1] = 10e5\n",
    "        for i in range(len(y_array)):\n",
    "            if y_array[i] < bottom[1]:\n",
    "                bottom[0] = x_array[i]\n",
    "                bottom[1] = y_array[i]\n",
    "        #cv2.rectangle(img,(left[0], up[1]),(right[0]+dev1, down[1]+dev2),(255,0,255),3)\n",
    "            \n",
    "        rectangle_calibrovka[0] = left[0]\n",
    "        rectangle_calibrovka[1] = top[1]\n",
    "        rectangle_calibrovka[2] = right[0]#+size_cell_x\n",
    "        rectangle_calibrovka[3] = bottom[1]#+size_cell_y\n",
    "                    \n",
    "        return rectangle_calibrovka\n",
    "\n",
    "def detect_marker (img, color):\n",
    "    #color = [hsv_min, hsv_max]\n",
    "    \n",
    "    # преобразуем RGB картинку в HSV модель\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # применяем цветовой фильтр\n",
    "\n",
    "    thresh = cv2.inRange(hsv, color[0], color[1])\n",
    "    \n",
    "    # вычисляем моменты изображения\n",
    "    moments = cv2.moments(thresh, 1)\n",
    "    dM01 = moments['m01']\n",
    "    dM10 = moments['m10']\n",
    "    dArea = moments['m00']\n",
    "    # будем реагировать только на те моменты,\n",
    "    # которые содержать больше 100 пикселей\n",
    "    \n",
    "    marker_coord = [0, 0]\n",
    "    if dArea > 100:\n",
    "        x = int(dM10 / dArea)\n",
    "        y = int(dM01 / dArea)\n",
    "        marker_coord[0] = x\n",
    "        marker_coord[1] = y\n",
    "        #cv2.circle(img, (x, y), 10, (0,0,255), -1)\n",
    "    return marker_coord\n",
    "\n",
    "def find_marker_place (img, marker_coord, size_cell_x, size_cell_y, color):\n",
    "    coord_rectang = [0, 0, 0, 0]\n",
    "    k_i = 0\n",
    "    l_j = 0\n",
    "    while k_i <= img.shape[1]:\n",
    "        while l_j <= img.shape[0]:\n",
    "            if x < k_i + size_cell_x and x > k_i and y < l_j + size_cell_y and y > l_j:\n",
    "                coord_rectang[0] = k_i\n",
    "                coord_rectang[1] = l_j\n",
    "                coord_rectang[2] = k_i+size_cell_x\n",
    "                coord_rectang[3] = l_j+size_cell_y\n",
    "                #cv2.rectangle(img,(k_i, l_j),(k_i+dev1, l_j+dev2),(0,255,255),3)                  \n",
    "            l_j+= dev2\n",
    "        k_i+= dev1\n",
    "        l_j = 0\n",
    "        \n",
    "    return coord_rectang\n",
    "\n",
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    \n",
    "    lst = list(dim)\n",
    "    lst[0] = int(lst[0])\n",
    "    dim = tuple(lst)\n",
    "    \n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    \n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    "def find_movement_of_man (curr_frame, back_frame, connectivity = 4):\n",
    "    #shape\n",
    "    shape = curr_frame.shape\n",
    "    \n",
    "    #make a photo of curr_frame\n",
    "    new_frame = cv2.imwrite('opencv1.png', curr_frame)\n",
    "    \n",
    "    #make a resize\n",
    "    back_frame_resize = image_resize(back_frame , width = shape[1]/4, height = shape[0]/4)\n",
    "    new_frame_resize = image_resize(new_frame , width = shape[1]/4, height = shape[0]/4)\n",
    "    \n",
    "    #filter\n",
    "    filtered_back_frame = cv2.blur (back_frame, (9, 9))\n",
    "    filtered_new_frame = cv2.blur (new_frame, (9, 9))\n",
    "    \n",
    "    #difference between photos\n",
    "    diff_between = cv2.absdiff(filtered_back_frame,filtered_new_frame)\n",
    "    \n",
    "\n",
    "    img_grey = cv2.cvtColor(diff_between, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gaussian_blur = cv2.GaussianBlur(img_grey, (5,5), 0)\n",
    "    \n",
    "    #binarization\n",
    "    _, frame = cv2.threshold(gaussian_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    kernel = np.ones((10,10),np.uint8)\n",
    "    erosia = cv2.erode(frame,kernel,iterations = 1)\n",
    "    \n",
    "    frame_end = image_resize(erosia , width = sh[1], height = sh[0])\n",
    "    \n",
    "    #find the lagest component of connectivity\n",
    "    output = cv2.connectedComponentsWithStats(d, connectivity, cv2.CV_32S)\n",
    "    \n",
    "    #rectangle around area\n",
    "    \n",
    "    new_rectangle_coord = [0, 0, 0, 0]\n",
    "    for i in range(output[0]):\n",
    "            if output[2][i][4] >= 5000: \n",
    "                new_rectangle_coord[0] = output[2][i][0]\n",
    "                new_rectangle_coord[1] = output[2][i][1]\n",
    "                new_rectangle_coord[2] = output[2][i][0] + output[2][i][2]\n",
    "                new_rectangle_coord[3] = output[2][i][1] + output[2][i][3]\n",
    "                #cv2.rectangle(d, (output[2][i][0], output[2][i][1]), \n",
    "                ####(output[2][i][0] + output[2][i][2], output[2][i][1] + output[2][i][3]), (255,0,255), 2)\n",
    "    \n",
    "    return new_rectangle_coord\n",
    "\n",
    "#ser = serial.Serial('/dev/tty.usbserial', 9600)\n",
    "\n",
    "arduino = PyCmdMessenger.ArduinoBoard(\"/dev/cu.usbmodem14101\",baud_rate=9600)\n",
    "\n",
    "# List of commands and their associated argument formats. These must be in the\n",
    "# same order as in the sketch.\n",
    "commands = [[\"who_are_you\",\"\"],\n",
    "            [\"my_name_is\",\"\"],\n",
    "            [\"sum_two_ints\",\"\"],\n",
    "            [\"sum_is\",\"\"],\n",
    "            [\"error\",\"\"]]\n",
    "\n",
    "def comanda(number):\n",
    "    # Initialize the messenger\n",
    "    c = PyCmdMessenger.CmdMessenger(arduino,commands)\n",
    "    if number == 1:\n",
    "        c.send(\"who_are_you\")\n",
    "        print('1')\n",
    "    if number == 2:\n",
    "        c.send(\"my_name_is\")\n",
    "        print('2')\n",
    "    if number == 3:\n",
    "        c.send(\"sum_two_ints\")\n",
    "        print('3')\n",
    "    if number == 4:\n",
    "        c.send(\"sum_is\")\n",
    "        print('4')\n",
    "    if number == 5:\n",
    "        c.send(\"error\")\n",
    "        print('5')\n",
    "        \n",
    "#number = 1\n",
    "#comanda(number)\n",
    "\n",
    "cv2.namedWindow (\"controller\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow (\"controller\", (WIND_X, WIND_Y))\n",
    "#cv2.resizeWindow (\"controller\", (WIND_X * 2, WIND_Y))\n",
    "\n",
    "cam = cv2.VideoCapture (0)\n",
    "ret, initial_frame = cam.read ()\n",
    "\n",
    "background = initial_frame.copy ()\n",
    "\n",
    "#measurements_num = 6 #measurements per series\n",
    "#series_num = 2\n",
    "\n",
    "time_limit     = 20\n",
    "measuring_mode = False\n",
    "movement_type  = 1\n",
    "\n",
    "start_time         = 0\n",
    "current_time       = 0\n",
    "time_passed        = 0\n",
    "robot_command_sent = False\n",
    "\n",
    "relax_mode    = False\n",
    "relax_timeout = 5\n",
    "\n",
    "#колпачок\n",
    "#marker_color_min = (53, 55, 147)\n",
    "#marker_color_max = (83, 160, 255)\n",
    "\n",
    "#резинка\n",
    "#marker_color_min = (190, 105, 165)\n",
    "#marker_color_max = (210, 130, 185)\n",
    "\n",
    "#шарик\n",
    "marker_color_min = (60, 130, 80)\n",
    "marker_color_max = (100, 170, 120)\n",
    "\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "calibration_mode = False\n",
    "\n",
    "curr_measurement_finished = False\n",
    "\n",
    "curr_time = time.time ()\n",
    "files_common_part = str (curr_time)\n",
    "\n",
    "fourcc1 = cv2.VideoWriter_fourcc (*'XVID')\n",
    "stream  = cv2.VideoWriter (\"log/\" + files_common_part + 'stream' + '.avi', fourcc1, 20.0, (WIND_X, WIND_Y))\n",
    "\n",
    "fourcc2 = cv2.VideoWriter_fourcc (*'XVID')\n",
    "cv      = cv2.VideoWriter (\"log/\" + files_common_part + 'cv' + '.avi', fourcc2, 20.0, (WIND_X, WIND_Y))\n",
    "\n",
    "log = open (\"log/\" + files_common_part + \"log.txt\", 'w')\n",
    "\n",
    "calib_marker_x = []\n",
    "calib_marker_y = []\n",
    "\n",
    "ip = \"http://192.168.1.183:\"\n",
    "port = \"9555\"\n",
    "\n",
    "rect_calib = [100, 100, 300, 250]\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cam.read ()\n",
    "    \n",
    "    #print (\"ffuu\", frame.shape)\n",
    "    #hsv_frame = cv2.cvtColor (frame, cv2.COLOR_BGR2HSV)\n",
    "    #cv2.imshow (\"hsv\", hsv_frame)\n",
    "    \n",
    "    stream.write (frame)\n",
    "    cv.write     (frame)\n",
    "    #log.write    (\"ffuu\")\n",
    "    \n",
    "    cv2.waitKey (1)\n",
    "    \n",
    "    frame_resized = cv2.resize (frame, (WIND_X, WIND_Y))\n",
    "    \n",
    "    current_time = time.time ()\n",
    "    time_passed = current_time - start_time\n",
    "    \n",
    "    marker = detect_marker (frame, (marker_color_min, marker_color_max))\n",
    "    \n",
    "    heigh = int ((rect_calib [3] - rect_calib [1]) / 3)\n",
    "    width = int ((rect_calib [2] - rect_calib [0]) / 4)\n",
    "    \n",
    "    if (measuring_mode == True):\n",
    "        cv2.putText (frame_resized, \"measuring mode on\", (10, 20), font, (200, 220, 240), 2, cv2.LINE_AA)\n",
    "    \n",
    "    else:\n",
    "        cv2.putText (frame_resized, \"measuring mode off\", (10, 20), font, (200, 220, 240), 2, cv2.LINE_AA)\n",
    "    \n",
    "    if (measuring_mode == True and relax_mode == False):\n",
    "        #send command to robot\n",
    "        if (robot_command_sent == False):\n",
    "            log.write (\"Sending command\", time.time ())\n",
    "            \n",
    "            mixer.init()\n",
    "            mixer.music.load(\"raise_hands.mp3\")\n",
    "            mixer.music.play()\n",
    "            \n",
    "            #send command\n",
    "            if (movement_type == 1):\n",
    "                log.write (\"Command type 1\", time.time ())\n",
    "                r = requests.get (ip + port + \"/?action=/left_hand_up&text=qwer\")\n",
    "            \n",
    "            if (movement_type == 2):\n",
    "                log.write (\"Command type 2\", time.time ())\n",
    "                r = requests.get (ip + port + \"/?action=/left_hand_left&text=qwer\")\n",
    "            \n",
    "            #if (movement_type == 3):\n",
    "            #    r = requests.get (ip + port + \"/?action=/left_shoulder_left&text=qwer\")\n",
    "            \n",
    "            #play sound\n",
    "            ###############################################\n",
    "            \n",
    "            robot_command_sent = True\n",
    "        \n",
    "        if (movement_type == 1 and\n",
    "            marker [1] < rect_calib [1] + heigh and\n",
    "            marker [1] > rect_calib [1] and\n",
    "            marker [0] < rect_calib [2] and\n",
    "            marker [0] > rect_calib [0]):\n",
    "            log.write (\"Movement 1 success\", time.time ())\n",
    "            \n",
    "            #r = requests.get (\"http://192.168.1.183:9555/?action=/green&text=qwer\")\n",
    "            #r = requests.get (ip + port + \"/?action=/left_hand_left&text=qwer\")\n",
    "            \n",
    "            comanda (1)\n",
    "            \n",
    "            #send command to haptics\n",
    "            curr_measurement_finished = True\n",
    "        \n",
    "        if (movement_type == 2 and\n",
    "            marker [1] > rect_calib [1] and\n",
    "            marker [1] < rect_calib [3] and\n",
    "            marker [0] < rect_calib [0] + width and\n",
    "            marker [0] > rect_calib [0]):\n",
    "            log.write (\"Movement 2 success\", time.time ())\n",
    "            \n",
    "            comanda (1)\n",
    "            \n",
    "            curr_measurement_finished = True\n",
    "\n",
    "        #if (movement_type == 3 and\n",
    "        #    marker [1] < rect_calib [1] + heigh and\n",
    "        #    marker [1] > rect_calib [1] and\n",
    "        #    marker [0] < rect_calib [2] and\n",
    "        #    marker [0] > rect_calib [0]):\n",
    "        #    print (\"success\")\n",
    "            \n",
    "        #    comanda (1)\n",
    "            \n",
    "        #    curr_measurement_finished = True\n",
    "        \n",
    "        log.write (\"Time passed\", time_passed)\n",
    "        \n",
    "        text = \"Passed time: \" + str (time_passed)\n",
    "        cv2.putText (frame_resized, text, (10, 50), font, (200, 220, 240), 2, cv2.LINE_AA)\n",
    "\n",
    "        if (time_passed > time_limit):\n",
    "            curr_measurement_finished = True\n",
    "    \n",
    "    if (curr_measurement_finished == True):\n",
    "        log.write (\"Entering relax mode\", time.time ())\n",
    "        \n",
    "        r = requests.get (ip + port + \"/?action=/stand&text=qwer\")\n",
    "        \n",
    "        curr_measurement_finished = False\n",
    "        \n",
    "        measuring_mode = False\n",
    "        \n",
    "        relax_mode = True\n",
    "        start_time = current_time\n",
    "        time_passed = 0\n",
    "    \n",
    "    if (relax_mode == True):\n",
    "        #print (\"relax\")\n",
    "        text = \"Passed relaxation time: \" + str (time_passed)\n",
    "        cv2.putText (frame_resized, text, (10, 50), font, (200, 220, 240), 2, cv2.LINE_AA)\n",
    "        \n",
    "        if (time_passed > relax_timeout):\n",
    "            relax_mode = False\n",
    "            start_time = current_time\n",
    "            time_passed = 0\n",
    "        \n",
    "    #analysis = frame_resized.copy ()\n",
    "    #cv2.rectangle (analysis, (0, 0), (WIND_X, WIND_Y), BACKGROUND_COLOR, thickness = -1)\n",
    "    \n",
    "    if (movement_type == 1):\n",
    "        cv2.line (frame_resized, (rect_calib [0], rect_calib [1] + heigh),\n",
    "            (rect_calib [2], rect_calib [1] + heigh), (100, 200, 100), 4)\n",
    "    \n",
    "    else:\n",
    "        cv2.line (frame_resized, (rect_calib [0] + width, rect_calib [1]),\n",
    "            (rect_calib [0] + width, rect_calib [3]), (100, 200, 100), 4)\n",
    "    \n",
    "    cv2.rectangle (frame_resized, (int (rect_calib [0]), int (rect_calib [1])),\n",
    "                   (int (rect_calib [2]), int (rect_calib [3])),\n",
    "                   (100, 200, 100), thickness = 5)\n",
    "    \n",
    "    cv2.circle (frame_resized, (marker [0], marker [1]), 10, (0,0,255), -1)\n",
    "\n",
    "    if (calibration_mode == True):\n",
    "        marker = detect_marker (frame, (marker_color_min, marker_color_max))\n",
    "        calib_marker_x.append (marker [0])\n",
    "        calib_marker_y.append (marker [1])\n",
    "        \n",
    "        #cv2.circle (analysis, (marker [0], marker [1]), 10, (0,0,255), -1)\n",
    "\n",
    "    #text\n",
    "    #time left to the end of the measurement\n",
    "    #number of current measurement/total number of measurements\n",
    "    #type of the movement\n",
    "    \n",
    "    #записать картинки в файлы\n",
    "    \n",
    "    #output = np.concatenate ((frame_resized, analysis), axis = 1)    \n",
    "    output = frame_resized    \n",
    "    #output = np.concatenate ((frame_resized, background), axis = 1)    \n",
    "\n",
    "    cv2.imshow (\"controller\", output)\n",
    "    \n",
    "    time.sleep (0.01)\n",
    "    keyb = cv2.waitKey (1)\n",
    "    \n",
    "    if (keyb & 0xFF == ord ('q')):\n",
    "        break\n",
    "\n",
    "    elif (keyb & 0xFF == ord ('s')):\n",
    "        measuring_mode = True\n",
    "        start_time = time.time ()\n",
    "\n",
    "    elif (keyb & 0xFF == ord ('f')):\n",
    "        measuring_mode = False\n",
    "\n",
    "    elif (keyb & 0xFF == ord ('1')):\n",
    "        measuring_mode = True\n",
    "        movement_type = 1\n",
    "\n",
    "    elif (keyb & 0xFF == ord ('2')):\n",
    "        measuring_mode = True\n",
    "        movement_type = 2\n",
    "    \n",
    "    elif (keyb & 0xFF == ord ('3')):\n",
    "        movement_type = 3\n",
    "    \n",
    "    #take background photo\n",
    "    elif (keyb & 0xFF == ord ('b')):\n",
    "        background = frame\n",
    "    \n",
    "    #start calibration\n",
    "    elif (keyb & 0xFF == ord ('c')):\n",
    "        log.write (\"Entering calibration mode\", time.time ())\n",
    "        calibration_mode = True\n",
    "    \n",
    "    #stop calibration\n",
    "    elif (keyb & 0xFF == ord ('v') and calibration_mode == True):\n",
    "        log.write (\"Calibration stopped\", time.time ())\n",
    "        \n",
    "        calibration_mode = False\n",
    "        rect_calib = calibration (calib_marker_x, calib_marker_y)\n",
    "        \n",
    "        #print (\"coords\", calib_marker_y)\n",
    "        \n",
    "        calib_marker_x.clear ()\n",
    "        calib_marker_y.clear ()\n",
    "    \n",
    "cam.release ()\n",
    "\n",
    "#закрыть файлы\n",
    "stream.release ()\n",
    "cv.release     ()\n",
    "log.close    ()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"start raise_hands.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "WAVEFormatException",
     "evalue": "AVbin is required to decode compressed media",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWAVEFormatException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4980927e3cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmusic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raise_hands.mp3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zenv/lib/python3.7/site-packages/pyglet/resource.py\u001b[0m in \u001b[0;36mmedia\u001b[0;34m(self, name, streaming)\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0;31m# needs to do it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstreaming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zenv/lib/python3.7/site-packages/pyglet/media/sources/loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, file, streaming)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \"\"\"\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_source_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstreaming\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStaticSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zenv/lib/python3.7/site-packages/pyglet/media/sources/loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, filename, file)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mriff\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWaveSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWaveSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zenv/lib/python3.7/site-packages/pyglet/media/sources/riff.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, file)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 raise WAVEFormatException(\n\u001b[0;32m--> 200\u001b[0;31m                     'AVbin is required to decode compressed media')\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwFormatTag\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mWAVE_FORMAT_PCM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWAVEFormatException\u001b[0m: AVbin is required to decode compressed media"
     ]
    }
   ],
   "source": [
    "import pyglet\n",
    "\n",
    "music = pyglet.resource.media('raise_hands.mp3')\n",
    "music.play()\n",
    "\n",
    "pyglet.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.io.mp3file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6953aeca7e44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp3file\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"raise_hands.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy.io.mp3file'"
     ]
    }
   ],
   "source": [
    "import scipy.io.mp3file as mp3\n",
    "from IPython.display import Audio\n",
    "\n",
    "rate, audio = wav.read (\"raise_hands.mp3\")\n",
    "Audio(audio, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mplayer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-21c2c96de36c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmplayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCmdPrefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Set default prefix for all Player instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mPlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmd_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCmdPrefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAUSING_KEEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mplayer'"
     ]
    }
   ],
   "source": [
    "from mplayer import Player, CmdPrefix\n",
    "\n",
    "# Set default prefix for all Player instances\n",
    "Player.cmd_prefix = CmdPrefix.PAUSING_KEEP\n",
    "\n",
    "# Since autospawn is True by default, no need to call player.spawn() manually\n",
    "player = Player()\n",
    "\n",
    "# Play a file\n",
    "player.loadfile('raise_hands.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'vlc' has no attribute 'MediaPlayer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-16aa805e4203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvlc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMediaPlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raise_hands.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'vlc' has no attribute 'MediaPlayer'"
     ]
    }
   ],
   "source": [
    "import vlc\n",
    "\n",
    "p = vlc.MediaPlayer(\"raise_hands.mp3\")\n",
    "p.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygame import mixer # Load the required library\n",
    "\n",
    "mixer.init()\n",
    "mixer.music.load(\"raise_hands.mp3\")\n",
    "mixer.music.play()\n",
    "\n",
    "#print (\"fuck\")\n",
    "#mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
