{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_marker (img, rect, color):\n",
    "    #color = [hsv_min, hsv_max]\n",
    "    \n",
    "    # преобразуем RGB картинку в HSV модель\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # применяем цветовой фильтр\n",
    "    thresh = cv2.inRange(hsv, color[0], color[1])\n",
    "    \n",
    "    # вычисляем моменты изображения\n",
    "    moments = cv2.moments(thresh, 1)\n",
    "    dM01 = moments['m01']\n",
    "    dM10 = moments['m10']\n",
    "    dArea = moments['m00']\n",
    "    # будем реагировать только на те моменты,\n",
    "    # которые содержать больше 100 пикселей\n",
    "    \n",
    "    marker_coord = [0, 0]\n",
    "    if dArea > 100:\n",
    "        x = int(dM10 / dArea)\n",
    "        y = int(dM01 / dArea)\n",
    "        marker_coord[0] = x\n",
    "        marker_coord[1] = y\n",
    "        #cv2.circle(img, (x, y), 10, (0,0,255), -1)\n",
    "    return marker_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_marker_place (img, marker_coord, size_cell_x, size_cell_y, color):\n",
    "    coord_rectang = [0, 0, 0, 0]\n",
    "    k_i = 0\n",
    "    l_j = 0\n",
    "    while k_i <= img.shape[1]:\n",
    "        while l_j <= img.shape[0]:\n",
    "            if x < k_i + size_cell_x and x > k_i and y < l_j + size_cell_y and y > l_j:\n",
    "                coord_rectang[0] = k_i\n",
    "                coord_rectang[1] = l_j\n",
    "                coord_rectang[2] = k_i+size_cell_x\n",
    "                coord_rectang[3] = l_j+size_cell_y\n",
    "                #cv2.rectangle(img,(k_i, l_j),(k_i+dev1, l_j+dev2),(0,255,255),3)                  \n",
    "            l_j+= dev2\n",
    "        k_i+= dev1\n",
    "        l_j = 0\n",
    "        \n",
    "    return coord_rectang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    \n",
    "    lst = list(dim)\n",
    "    lst[0] = int(lst[0])\n",
    "    dim = tuple(lst)\n",
    "    \n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    \n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    "\n",
    "def find_movement_of_man (curr_frame, back_frame, connectivity = 4):\n",
    "    \n",
    "    #shape\n",
    "    shape = curr_frame.shape\n",
    "    \n",
    "    #make a photo of curr_frame\n",
    "    new_frame = cv2.imwrite('opencv1.png', curr_frame)\n",
    "    \n",
    "    #make a resize\n",
    "    back_frame_resize = image_resize(back_frame , width = shape[1]/4, height = shape[0]/4)\n",
    "    new_frame_resize = image_resize(new_frame , width = shape[1]/4, height = shape[0]/4)\n",
    "    \n",
    "    #filter\n",
    "    filtered_back_frame = cv2.blur (back_frame, (9, 9))\n",
    "    filtered_new_frame = cv2.blur (new_frame, (9, 9))\n",
    "    \n",
    "    #difference between photos\n",
    "    diff_between = cv2.absdiff(filtered_back_frame,filtered_new_frame)\n",
    "    \n",
    "\n",
    "    img_grey = cv2.cvtColor(diff_between, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gaussian_blur = cv2.GaussianBlur(img_grey, (5,5), 0)\n",
    "    \n",
    "    #binarization\n",
    "    _, frame = cv2.threshold(gaussian_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    kernel = np.ones((10,10),np.uint8)\n",
    "    erosia = cv2.erode(frame,kernel,iterations = 1)\n",
    "    \n",
    "    frame_end = image_resize(erosia , width = sh[1], height = sh[0])\n",
    "    \n",
    "    #find the lagest component of connectivity\n",
    "    output = cv2.connectedComponentsWithStats(d, connectivity, cv2.CV_32S)\n",
    "    \n",
    "    #rectangle around area\n",
    "    \n",
    "    new_rectangle_coord = [0, 0, 0, 0]\n",
    "    for i in range(output[0]):\n",
    "            if output[2][i][4] >= 5000: \n",
    "                new_rectangle_coord[0] = output[2][i][0]\n",
    "                new_rectangle_coord[1] = output[2][i][1]\n",
    "                new_rectangle_coord[2] = output[2][i][0] + output[2][i][2]\n",
    "                new_rectangle_coord[3] = output[2][i][1] + output[2][i][3]\n",
    "                #cv2.rectangle(d, (output[2][i][0], output[2][i][1]), \n",
    "                ####(output[2][i][0] + output[2][i][2], output[2][i][1] + output[2][i][3]), (255,0,255), 2)\n",
    "    \n",
    "    return new_rectangle_coord"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
